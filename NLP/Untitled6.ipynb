{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import tokenizers\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from transformers import *\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Dense, Flatten, Conv1D, Dropout, Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    if (len(a)==0) & (len(b)==0): return 0.5\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "                vocab_file= 'vocab.json',\n",
    "                merges_file = 'merges.txt',\n",
    "                lowercase =True,\n",
    "                add_prefix_space = True\n",
    ")\n",
    "\n",
    "sentiment_id = {'neutral' : tokenizer.encode('neutral').ids[0],\n",
    "                'negative' : tokenizer.encode('negative').ids[0],\n",
    "                'positive' : tokenizer.encode('positive').ids[0]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = train_data.shape[0]\n",
    "input_ids = np.ones((temp,max_length),dtype='int32')\n",
    "attention_mask = np.zeros((temp, max_length),dtype='int32')\n",
    "token_type = np.zeros((temp,max_length),dtype='int32')\n",
    "start_mask = np.zeros((temp,max_length),dtype='int32')\n",
    "end_mask = np.zeros((temp,max_length),dtype='int32')\n",
    "\n",
    "for i in range(temp):\n",
    "    text1 = \" \"+\" \".join(train_data.loc[i,'text'].split())\n",
    "    text2 = \" \".join(train_data.loc[i, 'selected_text'].split())\n",
    "    index = text1.find(text2)\n",
    "    text2_loc = np.zeros((len(text1)))\n",
    "    text2_loc[index:index+len(text2)]=1\n",
    "    \n",
    "    if text1[index-1]==\" \": \n",
    "        text2_loc[index-1]=1\n",
    "    encode_text1 = tokenizer.encode(text1)\n",
    "    \n",
    "    s_text_token_index = []\n",
    "    \n",
    "\n",
    "   \n",
    "        \n",
    "    \n",
    "    for k,(x,y) in enumerate(encode_text1.offsets):\n",
    "        sum_val = np.sum(text2_loc[x:y])\n",
    "        if sum_val > 0:\n",
    "            s_text_token_index.append(k)\n",
    "        \n",
    "        \n",
    "    senti_token = sentiment_id[train_data.loc[i,'sentiment']]\n",
    "    input_ids[i,:len(encode_text1.ids)+5] = [0] +encode_text1.ids+[2,2]+[senti_token]+[2]\n",
    "    attention_mask[i,:len(encode_text1.ids)+5]=1\n",
    "    \n",
    "    if len(s_text_token_index) > 0:\n",
    "        start_mask[i,s_text_token_index[0]+1] = 1\n",
    "        end_mask[i, s_text_token_index[-1]+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(answer,prediction):\n",
    "    loss = tf.keras.losses.categorical_crossentropy(answer,prediction, from_logits = False , label_smoothing = 0.2)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    ids = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "    attention = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "    token = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "    PATH = '../NLP/'\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    roberta_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = roberta_model(ids,attention_mask=attention,token_type_ids=token)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "    x1 = tf.keras.layers.Conv1D(128,2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(64,2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "    x2 = tf.keras.layers.Conv1D(128,2,padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(64,2,padding='same')(x2)\n",
    "    x2 = tf.keras.layers.Dense(1)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[ids,attention,token], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-5)\n",
    "    model.compile(loss=loss_function,optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = test_data.shape[0]\n",
    "\n",
    "input_ids_test = np.ones((temp2,max_length),dtype='int32')\n",
    "attention_mask_test = np.zeros((temp2, max_length),dtype='int32')\n",
    "token_type_test = np.zeros((temp2,max_length),dtype='int32')\n",
    "\n",
    "for i in range(temp2):\n",
    "    text1 = \" \"+\" \".join(test_data.loc[i,'text'].split())\n",
    "    encode_text1 = tokenizer.encode(text1)\n",
    "    \n",
    "    senti_token = sentiment_id[test_data.loc[i,'sentiment']]\n",
    "    input_ids_test[i,:len(encode_text1.ids)+5] = [0] + encode_text1.ids + [2,2] + [senti_token] + [2]\n",
    "    attention_mask_test[i,:len(encode_text1.ids)+5] = 1\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 630s 6s/step\n",
      "111/111 [==============================] - 647s 6s/step\n",
      "111/111 [==============================] - 650s 6s/step\n"
     ]
    }
   ],
   "source": [
    "prediction_start= np.zeros((input_ids_test.shape[0],max_length))\n",
    "prediction_end= np.zeros((input_ids_test.shape[0],max_length))\n",
    "\n",
    "\n",
    "all_result = []\n",
    "\n",
    "for i in range(5):\n",
    "    K.clear_session()\n",
    "    model = build_model()\n",
    "    model.load_weights('v4-roberta-%i.h5'%4)\n",
    "    prediction = model.predict([input_ids_test,attention_mask_test,token_type_test],verbose = 1)\n",
    "    prediction_start = prediction_start + prediction[0]/3\n",
    "    prediction_end = prediction_end + prediction[1]/3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Encoding(num_tokens=16, attributes=[ids, type_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Encoding(num_tokens=31, attributes=[ids, type_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encoding(num_tokens=20, attributes=[ids, type_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>Encoding(num_tokens=4, attributes=[ids, type_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>Encoding(num_tokens=17, attributes=[ids, type_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "                                       selected_text  \n",
       "0  Encoding(num_tokens=16, attributes=[ids, type_...  \n",
       "1  Encoding(num_tokens=31, attributes=[ids, type_...  \n",
       "2  Encoding(num_tokens=20, attributes=[ids, type_...  \n",
       "3  Encoding(num_tokens=4, attributes=[ids, type_i...  \n",
       "4  Encoding(num_tokens=17, attributes=[ids, type_...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(input_ids_test.shape[0]):\n",
    "    x = np.argmax(prediction_start[i,])\n",
    "    y = np.argmax(prediction_end[i,])\n",
    "    if x>y:\n",
    "        update = test_data.loc[i,'text']\n",
    "    else : \n",
    "        text1 = \" \"+\" \".join(test_data.loc[i,'text'].split())\n",
    "        encode_1 = tokenizer.encode(text1)\n",
    "        update = tokenizer.decode(encode.ids[x-1:y])\n",
    "    all_result.append(encode)\n",
    "test_data['selected_text'] = all_result\n",
    "test_data.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[['textID','selected_text']].to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
